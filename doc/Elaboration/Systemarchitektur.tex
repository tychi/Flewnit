
\label{sec:systemArchitecture}

Dieses Kapitel soll ein Gefühl für die Komponenten von \emph{Flewnit} und 
ihre Zusammenhänge vermitteln. Die Komponenten "`in Aktion"' werden im Detail im Verlauf des Kapitels 
\ref{sec:simulation} beschrieben.
Dieses Kapitel soll die groben Konzepte und Ideen teilweise anhand von Beispielen vorstellen.
Nicht jedes Feature, welches erwähnt wird, ist auch tatsächlich vollständig implementiert und getestet.
Über den Status der Implementierung zum Zeitpunkt der Abgabe dieser Ausarbeitung
wird am Ende dieses Kapitels (Abschnitt \ref{sec:statusImplementation}) ein Überblick gegeben.

Das System wurde in C++ als (wahlweise statisch oder dynamisch zu linkende) Bibliothek implementiert.
Der Code der GPU-Programme ist in GLSL bzw. OpenCL C verfasst.

\subsection{Dependencies}
	\label{sec:dependencies}
	
	Zunächst sollen die verwendeten Third-Party-Bibliotheken kurz vorgestellt werden:

	\begin{description}
		\item[OpenGL3/4]
		Die schon mehrfach erwähnten modernen Versionen der \linebreak \emph{Open Graphics Library},
		der offenen API der Khronos Group zur \linebreak hardwarebeschleunigten Graphik-Programmierung 
		auf Basis der Dreiecks-Rasterisierung.
		\todo[color=green]{evtl treffenderen Ausdruck finden: Scanline-basiert oder was auch immer}
		Um die Programmierung ohne Legacy-Routinen nicht erst zur Laufzeit über einen OpenCL-Error
		durch Verwendung eines Core-Profiles zu erzwingen, gibt es einen OpenGL- Header
		namens "`gl3.h"'\footnote{beziehbar unter http://www.opengl.org/registry/},
		der in Kombination mit der entsprechenden Präprozessor-Definition
		\lstinline[language=C]|#define GL3_PROTOTYPES 1| schon zur Compile-Zeit nur die non-deprecated
		Routinen zur Verfügung stellt.
		
     	\item[OpenCL 1.0]
	    Die \emph{Open Computing Language}, erste Version der noch jungen API für massiv parallele Programmierung
	    \footnote{die GPGPU-Computing einschließt}, wie OpenGL von der Khronos Group verwaltet; 
	    sie stellt den ersten offenen Standard für GPGPU dar, d.h., die Verwendung der API ist nicht mehr an eine
	    bestimmte Hardware (wie bei Nvidia CUDA) oder ein bestimmtes Betriebssystem (wie Microsofts DirectCompute)
	    gebunden.
	    
	    Zur Zeit der Implementierung waren für Nvidia-GPUs noch keine Non-Developer-Treiber für OpenCL 1.1 verfügbar, 
	    außerdem gab es kein Feature dieser Version, welches dringend benötigt worden wäre.
	    Deshalb wurde die Version 1.0 verwendet.
	    
	    Es gibt einen C++ -Wrapper der C-API, welcher stark auf C++-Templates basiert und der in einer einzigen Headerdatei 
	    implementiert ist. Dieser ist direkt von der Khronos-Homepage\footnote{http://www.khronos.org/registry/cl/} 	
	    beziehbar. Dieser Wrapper wurde verwendet, da er die Nutzung der API wesentlich eleganter macht.
	    
    	
   		\item[GLFW 2.7]
		Wie auf Seite \pageref{focus:dependencies} angedeutet, waren folgende Dinge wichtig, damit die Einsetzbarkeit
		des Frameworks in professionelleren Kontexten nicht schon im Vorfeld verbaut ist:
		\begin{itemize}
			\item Option auf Fullscreen
			\item Option auf Multisampling
			\item Die Möglichkeit der Erstellung eines OpenGL-Kontextes einer frei wählbaren Version 
			mit Option zwischen Core- und Compatibility-Profile
			\item Option auf "`\emph{Mouse Grab}"', so dass man wie in einem Computerspiel mit ausgeblendetem Mauszeiger
			nur durch Bewegung der Maus ohne Bildschirm-/Fenster-Grenzen die virtuelle Kamera rotieren kann;
			\item "`Input events"', d.h. Aktualisierungen von Benutzereingaben sollen häufig und mit minimaler 
			Latenz geschehen, außerdem so unabhängig wie möglich von der Framerate sein.
			Nach Möglichkeit sollten Input-Updates zumindest "`aktiv abfragbar"' sein 
			(im Gegensatz zum passiven Warten darauf, dass von der Input-Library eine Callback-Funktion 
			aufgerufen wird).
			\item Es soll volle Kontrolle über die "Render-Loop" geben, so dass man nicht 
			den Kontrollfluss an eine Funktion übergibt, die womöglich nie zurückkehrt und weiteren Kontrollfluss
			durch das Benutzerprogramm	nur über Callback-Funktionen ermöglicht
			(wie \lstinline[language=C]|glutEnterMainLoop()| beim in die Jahre gekommenen \emph{GLUT}).
			Ein derartiges Konstrukt verhindert womöglich sauberes Herunterfahren und Neu-Initialisierung,
			wie es z.B. beim Wechseln einer Szene oder eines fundamentalen globalen Settings nötig sein könnte.	
		\end{itemize}
		\emph{GLFW}\footnote{http://www.glfw.org/} in der Version 2.7, die zum Zeitpunkt der Implementation aktuellste 
		stabile	Version, erfüllt diese Forderungen, und findet damit in \emph{Flewnit} Einsatz sowohl im Fenster- als auch 	
		im Input-Manager. Die Timing-Funktionalität wird ebenfalls von GLFW übernommen.
		
    	
    	\item[OpenGL Mathematics (GLM)]
    	Seit sämtlicher Mathematik-bezogener OpenGL-State inklusive zugehöriger built-in-Variablen und -Funktionen
    	wie \lstinline[language=GLSL]|gl_ModelViewProjectionMatrix| oder
    	\lstinline[language=GLSL]|ftransform()|
    	in GLSL abgeschafft wurden, führt um eine Bibliothek für Vektor- und Matrix-Algebra kein Weg mehr herum.
    	Es wurde sich für \emph{GLM}\footnote{http://glm.g-truc.net/} entschieden, da sie klein und dennoch mächtig ist,
    	und einige Convenience-Functions hat. QT hat ebenfalls eine Mathe-Bibliothek, verwendet jedoch
    	\lstinline[language=C]|double|, also 64bit-Fließkomma-Werte als Basis-Datentyp, was das direkte Übergeben
    	als Array von \lstinline[language=C]|float|-Uniforms an die OpenGL-Shader verhindert. Zwar unterstützen OpenGL
    	und moderne Graphikkarten \lstinline[language=C]|double| nativ, jedoch mit drastisch geringerer Geschwindigkeit,
    	da weniger Recheneinheiten für diesen Datentyp zur Verfügung stehen.\\
    	Die direkte Verwendung einer C++ - Mathe-Bibiothek mit überladenen Operatoren
    	und eigener Akkumulation von Matrizen vereinfacht den Umgang mit Matrix- Algebra
		im Vergleich zum zähen Hantieren mit der C-API zum Modifizieren des OpenGL-States mit seinen Matrix-Modes.
    	
    	\item[Grantlee]
    		\label{sec:archtitectured:dependencies:Grentlee}
	 		\lstset{language=GLSL} 
       		Die bereits erwähnte Template-Engine; die Syntax entspricht der der Template-Sprache des 
       		\emph{Django} Web Frameworks\footnote{https://www.djangoproject.com/}.\\

       		Es lassen sich durch die Applikation Werte an die Template-Engine übergeben, anhand derer
       		dann die Code-Generierung kontrolliert wird, bzw. welche durch Einschluss in doppelte
       		geschwungene Klammern direkt eingefügt werden können. \\
       		Beipiel:
			\begin{lstlisting}      		
vec4 fragmentColor =  	
	{% if SHADING_FEATURE_DIFFUSE_TEXTURING %}  
		texture(decalTexture,input.texCoords.xy);
	{% else %} color;
	{% endif %}  
			\end{lstlisting} 
			\begin{lstlisting}
#define NUM_BITS_PER_KEY_TO_SORT ( {{numBitsPerKey}} )
			\end{lstlisting} 
     		
       		Die Engine stellt einen Vererbungs-Mechanismus bereit:\\
       		Auf diese Weise kann z.B. die Datei "`particleSimulationTemplate.cl"' verschiedene "`Code-Blocks"'
       		definieren wie z.B.
       		
       		\begin{lstlisting}
{% block performSPHCalculations %}
	{% comment %}
	the core of the physics simulation: 
	accumulate all relevant values 
	(density, pressure force, viscosity force etc ...)
	{% endcomment %}               
{% endblock performSPHCalculations %}
       		\end{lstlisting}
       		
       		, die von anderen Dateien geerbt und entsprechend angepasst implementiert werden.\\
       		"`updateDensity.cl"' erbt von dieser Datei durch die Directive
       		\lstinline[language=GLSL]|{% extends "particleSimulationTemplate.cl" %}| 
       		und implementiert die Dichte-Berechnungen, 
       		ohne dass der umschließende (nicht unerheblich lange und komplexe) Kontrollfluss-Code wiederholt werden muss:
       		\begin{lstlisting}
{% block performSPHCalculations %}
	if( BELONGS_TO_FLUID(
			GET_CURRENT_NEIGHBOUR_PARTICLE_OBJECT_ID  ) )
	{
		ownDensity +=                   
			cObjectGenericFeatures [ GET_CURRENT_NEIGHBOUR_PARTICLE_OBJECT_ID  ].massPerParticle
			* poly6( ownPosition -  GET_CURRENT_NEIGHBOUR_POS , cSimParams );
	}
{% endblock performSPHCalculations %}
       		\end{lstlisting}

       		
       		
    	\item[Assimp]
    	Die \emph{Open Asset Import Library}\footnote{http://assimp.sourceforge.net/} ermöglicht das Auslesen
    	von Szenen direkt aus .blend-Dateien, dem nativen Datenformat des exzellenten Free Software -- 3D-
    	Modellierungsprogramms \emph{Blender}\footnote{http://www.blender.org/}.
    	Somit entfällt der umständliche Export in ein Zwischenformat.

    	
   		\item[TinyXML]
   		Um zu gewährleisten, dass das System schon in der frühen Entwicklungsphase weitgehend ohne 
   		Recompile-benötigende "`Hard-Codes"' konfigurierbar ist, wurde TinyXML verwended, um eine XML-
   		config-Datei zu parsen.    	
    
	
	\end{description}	

	Außerdem wurden manche Komponenten der \emph{Boost}-Libraries\footnote{http://www.boost.org/} verwendet.
	
	


\subsection{Klassendiagramm}

\begin{figure}[!h]
	\includegraphics[width=1.09\textwidth]{Overview_Flewnit_Architecture_After_Implementation1.pdf}
	%\includegraphics[width=\textwidth]{Overview_Flewnit_Architecture_After_Implementation1.pdf}
	\caption{Klassendiagramm des Gesamtsystems, Teil 1}
	\label{fig:ClassDiagOverview1}
\end{figure}


\begin{figure}[!h]
	\includegraphics[width=1.09\textwidth]{Overview_Flewnit_Architecture_After_Implementation2.pdf}
	%\includegraphics[width=\textwidth]{Overview_Flewnit_Architecture_After_Implementation2.pdf}	
	\caption{Klassendiagramm des Gesamtsystems, Teil 2}
	\label{fig:ClassDiagOverview2}
\end{figure}



Abbildung \ref{fig:ClassDiagOverview1} und \ref{fig:ClassDiagOverview2} zeigen ein vereinfachtes Klassendiagramm
von \emph{Flewnit}. Die roten Klassen stellen wichtige Meta-Informationen dar, um Kontrollfluss und Objekt-Erstellung
zu delegieren. In den folgenden Unterabschnitten werden die einzelnen Komponenten detaillierter vorgestellt.




 
\subsection{BasicObject und Memory Tracking}
	\lstset{language=C++} %we want c++ code listings
	
	Die Bibliothek soll zur Laufzeit kontrolliert herunterfahr- und re-initialisier-bar sein, 
	um eine vielseitige und flexible Anwendung zu gewährleisten. Da bei C++ das Speicher-Management dem
	Programmierer überlassen ist, und man daher vor allem bei massiver Nutzung von Pointern schnell den Überblick
	verliert, 
	\begin{itemize}
		\item welches Objekt welche anderen erschaffen hat,
		\item welche Objekte eine Klasse "`besitzt"' und somit für ihre Speicher-Freigabe zuständig ist bzw
		\item auf welche Objekte eine Klasse nur ein Handle für Verwaltung oder	Backtracking hat, ohne für Erschaffung
		 oder Löschung zuständig zu sein,
	\end{itemize}
	wurde in Anbetracht der oberen Forderung ein sehr simples Meta-Object-System realisiert, welches Klassen-Namen
	und Speicherverbrauch eines Objektes feststellt sowie jedem Objekt eine \emph{unique ID} zuweist.
	Zweck dieses Meta-Object-Systems war es, Speicherlecks durch Nicht-Löschen von Objekten während der Entwicklung 
	zu finden.
	
	Dafür erbt beinahe jede Klasse in \emph{Flewnit} von \lstinline|BasicObject|.
	Diese Klasse registriert sich automatisch bei der \lstinline|MemoryTracker|-Singleton-Instanz, bekommt dort eine
	ID zugewiesen. Diese ID hat noch keine Anwendung, könnte sich aber in einem Netzwerk-Kontext als nützlich erweisen.

	Wie bei Qt das \lstinline[language=C++]|Q_OBJECT|-Makro muss in jede von 
	\lstinline[language=C++]|BasicObject| erbende Klasse das Makro 
	\lstinline[language=C++]|FLEWNIT_BASIC_OBJECT_DECLARATIONS| eingetragen werden. Dieses Makro definiert die 
	Implementation einer virtuellen Funktion, welche die Meta-Informationen setzen:
    \begin{lstlisting}
#define FLEWNIT_BASIC_OBJECT_DECLARATIONS \
	public:\
		virtual void initBasicObject() \
		{ \
			mMemoryFootPrint = (int) sizeof(*this); \
			mClassName = String(typeid(*this).name()); \
		} \
	private:	
	\end{lstlisting}
	Diese umständliche Implementierung hat die Ursache, dass Typ-Informationen der Blatt-Klasse einer
	Klassenhierarchie erst dann zur Verfügung stehen, wenn alle Konstruktoren der Basis-Klassen zurückgekehrt sind,
	weshalb der obere Code also nicht im Konstruktor der Basisklasse stehen darf, da der \lstinline|this|-Pointer
	noch nicht die Informationen der Blatt-Klasse enthält.
	Ferner, um dem Programmierer nicht zuzumuten, \lstinline|initBasicObject()| in jedem Konstruktor aufzurufen
	(das führt bei tiefen Klassenhierarchien zu unnötigen Ausführungen dieser Funktion, da nur die Info der Blatt-Klasse
	benötigt wird, außerdem entstünde so eine weitere Vergesslichkeits-Fehlerquelle, die durch das Meta Object-System ja 
	gerade \emph{vermieden} werden soll), stellt der Memory Tracker eine Routine \lstinline|updateMemoryTrackingInfo()|
	bereit, die aufgerufen werden sollte, wenn man auf valide Meta-Information zugreifen will.
	Aufpassen muss man bei tiefen Klassenhierarchien, da hier der Compiler keinen Fehler erzeugt, wenn eine Blatt-Klasse
	das Makro nicht eingetragen hat, da eine Implementierung der Funktion bereits durch eine Oberklasse existiert.
	
	Über bedingte Kompilierung lässt sich diese Meta-Funktionalität deaktivieren.
	Ein "`richtiges"' Meta Object-System wie das von Qt sollte keine Verwendung finden, 
	da es für die Zwecke dieses Frameworks zu komplex und mächtig ist, und nicht 
	mit Kanonen auf Spatzen geschossen werden sollte. Ohnehin gibt es Tools wie Valgrind, mit denen
	man Speicherlecks finden kann. 

	Letztendlich ist diese Lösung nicht wirklich elegant (auch wenn ich ohne Meta-Object-Compiler (MOC) keine bessere 	
	Lösung gefunden habe) und daher eher als eine Spielerei anzusehen
	mit dem Zwecke, die C++-Interna zu verinnerlichen und zu jeder Zeit daran erinnert zu werden, 
	Destruktoren zu implementieren und sich über 
	"`Besitz- und Verwaltungs-Verhältnisse"' der Klassen Gedanken zu machen.
	
	Der \lstinline|MemoryTracker| verfolgt auch sämtliche Allokationen der \lstinline|BufferInterface|-Klasse,
	also der Basisklasse sämtlicher Buffer-Typen.
	
\subsection{AmendedTransform}
	\label{sec:AmendedTransform}
 	Im Zuge der Überlegungen zum Szenegraphen, der Kamera und des visuellen Renderings vieler Objekte per
 	Hardware-Instancing fiel die Entscheidung, die klassische 4x4-Transformationsmatrix zu wrappen und mit
 	Convenience Functions anzureichern, siehe Listing \ref{listing:AmendedTransformDef}.\\
 	Der Zweck dieser Klasse ist es, Transformationsmatrizen anhand "`anschaulicher"' Parameter 
 	(Position, Richtung, Up-Vektor, Skalierung) zu definieren,
 	und diese Parameter auch nach Akkumulationen, Modifikationen und/oder Animationen zur Verfügung zu haben.\\
 	Der Fokus liegt hier klar auf der Bequemlichkeit für den Entwickler, nicht auf der Performance.
 	Sobald sehr große, dynamisch animierte und tiefe Szenegraphen zum Einsatz kommen, könnte diese Klasse
 	zum Flaschenhals werden. Dann ist vielleicht ein Refactoring vonnöten. Vorerst scheint mir die Implementation jedoch
 	angemessen.\\
 	
 	So lässt sich z.B. bequem ein \lstinline|Camera|-Objekt, welches selber von \lstinline|WorldObject| erbt,
 	welches wiederum von \lstinline|SceneNode| abgeleitet ist, an eine andere SceneNode anhängen, und aus der automatisch
 	berechneten globalen Transformation erhält man durch \lstinline|AmendedTransform::getLookAtMatrix()|
 	direkt die lookAt-Matrix, so  dass die Camera-Klasse selber sich nur noch um ihre Projektionsmatrix kümmern muss.
 	Auch typische Animationen werden von der Klasse übernommen. Ob dies guter Stil ist, oder doch lieber in die
 	SceneNode-Klasse ausgelagert werden sollte, ist eine Frage, die ich noch nicht abschließend beantworten kann.
 	Es wurde hier dem Paradigma der Datenlokalität gefolgt, evtl. auf Kosten der Separation of Concerns.
 	Eine weitere Erörtertung lasse ich aus, da das Refactoring in diesem Falle nicht zu aufwändig wäre.

	Es sei bemerkt, dass die Menge an Matrizen, die an den Vertex Shader beim Instanced Rendering übergeben
	werden müssen, wenn man für alle Fälle gewappnet sein will
	\footnote{z.B. für Layered Rendering in verschiedene Texturen, z.B in ein Textur-Array zur Generierung mehrerer 
	Spotlight-Shadowmaps mit einem Draw-Call; hierbei braucht es explizit nur die Model Matrix, da es pro Layer 
	verschiedene View-Matrices (pro Spotlight eine) gibt, von daher nicht im Vorfeld eine ModelView Matrix akkumuliert 
	werden kann.}
	, nicht unerheblich ist, da für jede Instanz ein anderes Matrix-Set übergeben werden muss.
	Die Menge an Daten, die per Uniform-Variable übergeben werden kann, ist begrenzt, daher hängt die maximale Anzahl
	an Instanzen, die pro Draw-Call gezeichnet werden können, direkt davon ab, wie viele Daten pro Instanz übergeben 
	werden müssen.\\
	Dieser Umstand hat dazu verführt, die Normal Matrix, die transponierte Inverse der ModelView-Matrix,
	"`einzusparen"': da Normalen und Tangenten durch Interpolation für den Fragment Shader ohnehin normalisiert werden 
	müssen, spielt beim Ergebnis  der Transformation eines Vektors 
	\footnote{mit homogener Koordinate 0,im Gegensatz zu Punkten, homog. Koord. 1} 
	nur die Richtung eine Rolle, nicht der Betrag. Die Richtung ändert sich nicht,
	wenn eine uniforme Skalierung in der Matrix steckt, wenn also der Skalierungsfaktor pro Raumdimension überall gleich 
	ist. Der Translations-Anteil einer Matrix spielt bei Vektoren keine Rolle. Aus diesen Umständen lässt sich folgern, 
	dass man zur Transformation von Vektoren ebenfalls die Model- bzw ModelView- Matrix verwenden kann, 
	und \emph{keine} dedizierte Normal Matrix braucht,
	solange nur Translation, Rotation und uniforme Skalierung in der Matrix akkumuliert sind.\\
	Eben dies versuche ich, durch die \lstinline|AmendedTransform|-Klasse zu forcieren, indem nur ein eingeschränkter
	\lstinline|public|-Konstruktor existiert, direkte Initialisierung per Matrix-Konstruktor nur für bestimmte
	\lstinline|friend|-Klassen erlaubt sind, und auch dann diese Matrix validiert wird.
	Die Einschränkung erscheint legitim, da eine Uniform Rendering Engine den Anspruch hat, zumindest
	im Ansatz "`physikalisch basiert"' zu sein. Deshalb sollten sich  Skalierungen ohnehin nur selten
	zur Laufzeit ändern, und dann nur einheitlich. So kann man im Vorfeld die Geometrie so anpassen, 
	dass keine nicht-uniforme Skalierung in der Transformationsmatrix auftaucht.
	
	
	Eine \lstinline|AmendedTransform| ist insofern mit der \lstinline|SceneNode|-Klasse verzahnt, dass falls eine
	\lstinline|AmendedTransform|-Instanz als Tranformation einer Scene-Node dient, erstere ein Handle auf die Scene Node 
	bekommt. Auf diese Weise kann die Scene Node immer automatisch informiert werden, wenn sich bei der 
	\lstinline|AmendedTransform| etwas geändert hat (es müssen dann ggfs. die Kinder der Scene-Node aktualisiert werden,
	z.B. für eventuelles Update von Bounding Boxes). Auf diese Weise muss weder die \lstinline|AmendedTransform|
	nochmal durch die \lstinline|SceneNode| gewrappt werden, noch können Seiteneffekte durch direkte Manipulation der 
	Transformation auftreten, sollte der Programmierer vergessen, anschließend die Scenenode über ihre 
	Transformations-Änderung zu informieren.
	Die Scene-Node-Kopplung ist rein intern und braucht den Benutzer der Klasse nicht weiter zu interessieren,
	außer in der Hinsicht, dass Scene-Node-Manipulation direkt geschieht und die \lstinline|SceneNode|-Klasse
	kein eigenes Interface zur Manipulation von Tranformationen bereit stellt.
	
 	
 	\begin{lstlisting}[caption={AmenededTransform Klassendefinition, gekürzt},label=listing:AmendedTransformDef]
class AmendedTransform
{
public:
	AmendedTransform(
			const Vector3D& position = Vector3D(0.0f,0.0f,0.0f),
			//(0,0,-1) is assumed as initial orientation, extress any deviation in euler angles(radians)
			const Vector3D& direction = Vector3D(0.0f,0.0f,-1.0f),
			const Vector3D& upVector = Vector3D(0.0f,1.0f,0.0f),
			float scale = 1.0f);
	AmendedTransform(const AmendedTransform& rhs);
	virtual ~AmendedTransform();

	AmendedTransform operator*(const AmendedTransform& rhs)const;
	//the assignment operators copy only the transformation values, not the SceneNode-Related info
	const AmendedTransform& operator*=(const AmendedTransform& rhs);
	const AmendedTransform& operator=(const AmendedTransform& rhs);

	//accum: translationMatrix * rotationMatrix * scaleMatrix;
	const Matrix4x4& getTotalTransform()const;
	//convenience functions:
	//unscaled, i.e. orthonormal rotation matrix:
	Matrix3x3 getRotationMatrix()const;
	//inverse of (translationMat*rotationMat);
	Matrix4x4 getLookAtMatrix()const;
	Matrix4x4 getScaleMatrix()const;
	Matrix4x4 getInverseScaleMatrix()const;
	static bool matricesAreEqual(const Matrix4x4& lhs, const Matrix4x4& rhs);
	AmendedTransform getInverse()const;

	/*... getter and setter for pos, dir, up omitted */ 

	//"animation" functions:
	void moveRelativeToDirection(float forwardBackward, float rightLeft, float upDown);
	//change direction by rotating it angleDegrees degrees around cross(direction,upVector)
	void pitchRelativeToDirection(float angleDegrees);
	//change direction by rotating it angleDegrees degrees around the upVector;
	void yawRelativeToUpVector(float angleDegrees);

protected:
	//backtrace pointer to tell the scene node to update itself after its transform has been modified directly;
	//mOwningScenNode->transformChanged(bool global) will be called by any setter function of this class if there is an
	//associated SceneNode;
	SceneNode* mOwningSceneNode;
	//flag needed by Scene node to update itself appropriately
	bool mIsGlobalTransform;
	
	friend class SceneNode;
	void setOwningSceneNode(SceneNode*node, bool isGlobalTransform)
		{mOwningSceneNode = node; mIsGlobalTransform=isGlobalTransform;}


	Vector3D mPosition;
	Vector3D mDirection;
	Vector3D mUpVector;
	float mScale;
	
	Matrix4x4 mAccumTranslationRotationScaleMatrix;

	//construct the transformation matrix from current pos,dir,up,scale; is called by any constructor and related setter;
	//validates members, if possible
	void setup();


	friend class Loader;//the loader may set transformation matrices, as they are read directly from Scene descriptions ;)
	//protected matrix-constructor to omit that the user passes a non-conforming matrix	
	AmendedTransform(const Matrix4x4& transform);
	
};
 	\end{lstlisting}
 	
 	

    	
    	
    	
\subsection{Die \emph{Unified Rendering Engine} (URE)}
	Dies ist die Singleton-Klasse, die sämtliche Komponenten besitzt/verwaltet, und über welche direkt oder indirekt alle 
	Daten beschafft oder Funktionalität aufgerufen werden kann, die nach außen hin verfügbar sein soll.

\subsection{Das UserInterface-Paket}
	Das User Interface hat ein abstraktes Window-Manager-Interface, welches von einer Implementation, die \emph{GLFW} 	
	verwendet, realisiert wird.
	Aus der geparsten Config wird die gewünschte OpenGL-Kontext-Version, Auflösung, Multisamples-Count, Fullscreen-Option
	etc. ausgelesen und ein entsprechendes Fenster mit OpenGL-Kontext erzeugt.\\

	Die Input-Verwaltung ist im Gegensatz zum Fenstermanager nicht vollständig von der verwendeten Input-Bibliothek 	
	(ebenfalls GLFW) abstrahiert, da beim Parsen des Inputs die von GLFW definierten Makros direkt verwendet werden, 
	 wie z.B \lstinline|GLFW_KEY_ENTER|.
	Da die Austauschbarkeit von verwendeten Bibliotheken zwar erwünscht ist, aber der Fokus nicht aus den Augen 
	verloren werden sollte, bleibt die Abstraktion des Inputs noch ein langfristiges "`TODO"' mit geringerer Priorität.

	Eine GUI wurde leider noch nicht implementiert, vor allem aus dem Grund, dass vorhandene GUI-Toolkits wie z.B.
	\emph{AntTweakBar}\footnote{http://www.antisphere.com/Wiki/tools:anttweakbar} Legacy-OpenGL-Routinen verwenden,
	was die Verwendung eines modernen Core-Profiles ausschließen würde.
	Da langfristig ein konsistentes Erscheinungsbild angestrebt wird, welches seine GUI vollständig in das 
	OpenGL- Rendering-Fenster integriert hat, kam auch die  Verwendung von GUI-Toolkits wie dem von Qt nicht in Frage.\\
	Letztendlich wollte ich schon immer eine kleine GUI entwickeln, wozu ich jedoch erwartungsgemäß im Rahmen dieser
	Arbeit keine Zeit hatte. Die GUI verbleibt also als ein "`TODO"' von mittlerer Priorität.




\subsection{Das Simulator-Paket}

	\begin{figure}[!h]
		 \includegraphics[width=1.15\textwidth]{Detail_Simulator.pdf}
		\caption{Grobes Beispiel von einer Simulation und den zugehörigen Daten-Abhängigkeiten}
		\label{fig:detailSimulator}
	\end{figure}


	Wie bereits erwähnt, soll jede Simulationsdömane einen eigenen Simulator haben, 
	der eine eigene Pipeline an Simulations-Stages verwaltet.
	Es kann theoretisch beliebig viele Simulationsdomänen geben. Momentan sind jedoch nur drei
	über einen \lstinline|enum| definiert: Die visuelle, mechanische und akustische Domäne, wobei
	die akustische Domäne noch nicht in der prototypischen Implementierung vorkommt.
	Abb. \ref{fig:detailSimulator} zeigt grob beispielhaft den Ablauf einer Simulation und die verschiedenen
	Varianten, wie man sich die "`Rendering Results"' anderer Stages beschaffen kann:\\
	Entweder aus der Main Loop der Engine heraus oder von der benutzenden Applikation wird
	\lstinline|URE::stepSimulation()| aufgerufen. Diese Funktion iteriert in fester Reihenfolge über die
	vorhandenen Simulatoren und ruft deren \lstinline|stepSimulation()|-Routine auf. Hierin werden Simulator-
	spezifische Operationen ausgeführt (Framebuffers des Fensters resetten und Haupt-Viewport setzen beim 
	\lstinline|LightingSimulator|, CL/GL-shared Buffers für OpenCL akquirieren beim \lstinline|MechanicsSimulator| ...),
	dann über die einzelnen zugehörigen	\lstinline|SimulationPipelineStage|'s iteriert, wiederum deren 
	\lstinline|stepSimulation()|-Methode aufgerufen.
	Hier passiert dann das eigentliche \emph{generische Rendering}.
	So verschieden die Algorithmen sind, die in den einzelnen Stages abgearbeitet werden, so verschieden sind auch
	die Möglichkeiten, wie einzelne Stages miteinander Daten austauschen: Der generischste Ansatz ist, sich von einer
	Stage einen Buffer mit einer bestimmten Semantik zu beschaffen, sofern die entsprechende Stage einen solchen
	bereit stellt. Bei Lichtsimulation, die viel mit Texturen und OpenGL-Framebuffer-Objects (FBOs) umgeht,
	bietet sich an, sich das \lstinline|RenderTarget| (die Abtraktion des FBO in \emph{Flewnit}) zu beschaffen,
	um mit dem gesamten \lstinline|RenderTarget| weiter zu arbeiten, oder sich einzelne Texturen zu beschaffen.
	Es gibt aber auch die relativ indirekte Methode des Datenaustausches, wie es z.B. zwischen der 
	\lstinline|ParticleMechanicsStage| und der \lstinline|ParticleLiquidDrawStage| der Fall ist: Die Buffer mit den 		
	physikalischen Attributen sind in der SceneNode-abgeleiteten
	Klasse \lstinline|ParticleFluid| enthalten, so dass die aktualisierten Daten über schlichtes Szenegraphen-Traversieren
	beschafft werden können.\\
	Details zum Ablauf der Simulation(en) werden in Kapitel \ref{sec:simulation} behandelt.




\subsection{Der SimulationResourceManger}
	Diese Singleton-Klasse besitzt und verwaltet die Assets,\linebreak 
	als \lstinline|std::map<String,X*>| für Referenzierung über einen Namen, 
	wobei \lstinline|X| folgende Klassen betrifft: 
	\begin{itemize}
		\item \lstinline|Material|
		\item \lstinline|Geometry|
		\item \lstinline|BufferInterface|
		\item \lstinline|Texture| \footnote{Da \lstinline|Texture| von \lstinline|BufferInterface| erbt, 
		handelt es sich um eine Handle-Sammlung der Untermenge der Texturen aller \lstinline|BufferInterface|s,
		um einen bequemeren Zugriff zu ermöglichen}
		\item \lstinline|InstanceManager|
	\end{itemize}
	Außerdem bestitzt die Klasse den \lstinline|SceneGraph| und stellt einen Handle auf den aktuellen 
	\lstinline|SkyDome| zur Verfügung, so dass alle Objekte ein konsistentes Environment Mapping 
	betreiben können, sofern dies erwünscht ist.

		
\subsection{Das Scene-Paket}		
	Neben dem klassischen Szene-Graphen, der vor allem im Kontext des visuellen Echtzeit-Rendering verwendet wird,
	da er Culling und relative Transformationen ermöglicht, 
	erfordern verschiedene Simulationsdomänen und Repräsentationen der beteiligten Simulations-Objekte
	(z.B. als Dreiecks-Mesh, Komposition von komplexeren Primitiven, Punktwolke oder Voxel-Grid)  ggfs. 
	unterschiedliche Szene-Repräsentationen, damit die spezifischen Anforderungen der Simulation als solchen und der
	Respräsentation der simulierten Objekte optimal erfüllt sind.\\
	Diese Szenen-Repräsentationen unterscheiden sich in der logischen Organisation ihrer Objekte 
	(z.B. Baumstruktur, sortierte oder unsortierte Sammlung, Graph-Struktur, Voxel-Struktur) 
	und in den Meta-Informationen, welche für die einzelnen	Objekte notwendig sind.
	
	Beispielsweise stellt die effiziente Suche nach räumlich benachbarten Objekten eine wichtige Anforderung
	bei vielen Simulationen (auch bei Lichtsimulation für globale Beleuchtungseffekte) dar.
	Hierfür bieten sich verschiedene Beschleunigungsstrukturen an. Je nach Simulationsdomäne, 
	Objekt-Repräsentation,verwendetem Simulations-Verfahren, verwendeter Hardware und Zielsetzung 
	(Geschwindigkeit, Genauigkeit, Speicherverbrauch...) sind verschiedene Beschleunigungsstrukturen angemessen.
	Somit besteht keine 1:1-Verbindung zwischen Szenen-Repräsentation und Beschleunigungsstruktur.\\
	Beschleunigungsstruktur und Szenen-Repräsentatioen sind somit nur lose gekoppelt.
	Um die verschiedenen Zwecke zu verdeutlichen, stellt Tabelle \ref{tab:sceneRepVsAccStruct} diese gegenüber.


	\begin{table}	 	
	 	\begin{tabular}
  		{ x{0.33\textwidth} | x{0.33\textwidth} | x{0.33\textwidth} | }	
  					\cline{2-3}
  					& Szenen-Repräsentation & Beschleunigungsstruktur
  					\tabularnewline\cline{1-3}
  		\multicolumn{1}{ |c| }{
  			Organisation der Elemente
  		}			&	
  						logisch für Zugriff auf Ebene der Anwendungslogik
  					&  
						räumlich für effizienten Zugriff durch einen Simulations-Algorithmus
  			 		\tabularnewline\cline{1-3}
   		\multicolumn{1}{ |c| }{
  			Zweck von Meta-Informationen
  		}			&
  						verschieden, je nach Repräsentation und Typ der Simulations-Objekte	
  					&	
  						(sofern vorhanden) unterschliedlich für verschiedene Algorithmen, z.b.
 						effiziente Traversierung und/oder Nachbarschaftssuche
  					\tabularnewline\cline{1-3}	  	  	
	  	\end{tabular}	  	
  		\caption{Gegenüberstellung der Zwecke einer generischen Szenen-Repräsentation und einer Beschleunigungsstruktur}
  		\label{tab:sceneRepVsAccStruct}
	\end{table}	
	
	Es gibt also zwei Basis-Klassen, wie in Abb. \ref{fig:ClassDiagOverview2} zu sehen ist:
	\lstinline|SceneRepresentation| und \lstinline|AccelerationStructure|.
	\lstinline|AccelerationStructure| erbt von \lstinline|WorldObject|(siehe Abschnitt \ref{sec:worldObject}),
	um optional Debug-Draw-Funktionalität bereit zu stellen.
	Ansonsten handelt es sich schlicht um abstrakte Basis-Klassen ohne weitere Funktionalität.
	
	Für das gesamte System über den \lstinline|SimulationResourceManger| verfügbar ist der
	\lstinline|SceneGraph|. Dieser enthält die Wurzel-\lstinline|SceneNode|, welche beliebig viele Kinder derselben
	Klasse haben kann. Somit wird eine Baumstruktur gebildet.\\
	Die SceneNode bildet die Basis-Klasse des \lstinline|WorldObject| (siehe Abschnitt \ref{sec:worldObject}).
	
	Es ist ein Mechanismus konzipiert, sowohl Kinder als auch Vorfahr über Änderungen der eigenen Transformation
	und/oder Bounding Box zu informieren, so dass ggfs. globale Transformationen akkumuliert werden können und/oder
	die Bounding Box für den eigenen Unterbaum ermittelt, die für Culling-Berechnungen verwendet werden kann.
	Noch ist dieses Feature nicht in Nutzung und seine Implementation unvollständig und ungetestet,
	daher wird auf weitere Details	verzichtet.
	
	Die klassischen Operationen (Einfügen, Aushängen, rekursives Suchen im Unterbaum nach Namen, Node bewegen,
	Transformationen akkumulieren) sind jedoch implementiert. Es sei an die enge Kopplung dieser Klasse an
	\lstinline|AmendedTransform| (s. Abschnitt \ref{sec:AmendedTransform}) erinnert.
	
	Der Scenegraph kann nach dem Visitor- Design Pattern traversiert werden. Z.B. erbt 
	\lstinline|SimulationPipelineStage| von \lstinline|SceneNodeVisitor|, so dass bei Bedarf eine Pipeline-Stage
	nur \lstinline|virtual void visitSceneNode(SceneNode* node)| implementieren muss, um Operationen auf oder mit
	den Objekten des Szenegraphen auszuführen.
	Momentan "`besitzt"' die \lstinline|SceneNode|-Klasse seine Kinder, was den Vorteil hat, dass die Nodes nicht woanders
	verwaltet werden müssen, aber den Nachteil, dass ausgehängte Scene Nodes nicht automatisch beim Reset der Engine
	gelöscht werden. Sollte sich dies später als Problem herausstellen, könnte man die Scene Nodes auch vom
	\lstinline|SimulationResourceManger| verwalten lassen.
	Auch empfiehlt sich langfristig die Möglichkeit zur Erschaffung und Verwaltung mehrerer Szenegraphen.
	Aus Zeitgründen wurde es jedoch erst einmal bei dieser rudimentären Implementation belassen.
	
	Intern verwaltet die \lstinline|ParticleMechanicsStage| (die  \linebreak \lstinline|SimulationPipelineStage|,
	welche im \lstinline|MechanicsSimulator| für die partikelbasierte Simulation zuständig ist), 
	eine \lstinline|ParticleSceneRepresentation|. Diese verwaltet 
	\begin{itemize}
		\item die "`makroskopischen Objekte"', die an dieser Simulation teilnehmen,
		namentlich (allesamt von \lstinline|WorldObject| abgeleitete) 
		partikelbasierte Fluide, partikel-repräsentierte Rigid Bodies und statische Kollisions-Meshes
		\footnote{diese müssen in einem bestimmten Format vorliegen}
		\item die einzelnen Attribute-Buffers der Partikel
			(Position, Dichte, Geschwindigkeit, Beschleunigung usw.)
		\item Buffers mit Meta-Informationen der "`makroskopischen Objekte"', die an OpenCL-Kernels übergeben werden
	\end{itemize}
	Ferner stellt die Klasse Factory-Methoden für die makroskopischen Objekte bereit, da diese direkt mit den
	Partikel-Buffern assoziiert sind, sich also alle beteiligten Objekte die Buffers teilen müssen. Die korrekte
	Delegierung der Offsets und Sicherstellung der richtigen Größen wird so übernommen.\\
	Die \lstinline|ParticleMechanicsStage| nutzt außerdem ein \lstinline|UniformGrid| für die Simulation.
	Details hierzu werden im Verlauf des Kapitels \ref{sec:mechanicalDomain} beschreiben.
	
	


\subsection{Das WorldObject}
	\label{sec:worldObject}
	Das \lstinline|WorldObject| stellt die abstrakte Basisklasse für sämtliche Objekte dar, mit denen eine oder mehrere 
	Simulationen durchgeführt werden sollen\footnote{Und sei es nur Debug Drawing. Selbst dies kann als eine 
	rudimentäre Form von Lichtsimulation aufgefasst werden.}. Sie erbt von \lstinline|SceneNode|. Damit ist sie bequem 
	in den Szenegraphen integrierbar und hat außerdem schon seine Transformations-Membervariable.
	
	Bei dieser Klasse zeigt sich erstmals die angestrebte Symmetrie zwischen den Simulationsdömanen: 
	Für jede Simulationsdomäne
	gibt es eine (möglicherweise leere) Liste an \lstinline|SubObject|'s. Das \lstinline|SubObject| 
	stellt eine Abstraktion dessen dar, was in einer klassischen Graphik-Engine ein "`SubMesh"' oder
	in einer klassischen Physik-Engine eine Komponente einer "`(Compound) Collision Shape"' sein könnte.\\
	Ein \lstinline|SubObject| hat immer einen Pointer auf genau ein \lstinline|Material|, 
	eine \lstinline|Geometry|  und für Backtracking-Zwecke auf sein besitzendes	\lstinline|WorldObject|.
	Wie der Backtracking-Pointer andeutet, besitzt ein \lstinline|WorldObject| jedes seiner \lstinline|SubObject|s.
	Die vom \lstinline|SubObject| genutzte Geometrie und Materialien können jedoch --sofern sinnvoll -- von beliebig
	vielen \lstinline|SubObject|s gemeinsam genutzt werden.
	
	Es sind verschiedenste Ableitungen von \lstinline|WorldObject| denkbar, z.B. 
	(standard/particle based/voxel based) Rigid Body, Soft Body, rein visuelles Objekt,  
	Kamera,Lichtquelle, Debug-Draw-Objekte, Cloth, Hair, oder (particle based/voxel based) Fluid.
	
	Welche Objekte im Szenegraph für die Nutzung in einer Simulations-Stage in Frage kommen, lässt sich entweder
	über eine Vorfilterung bei Objekt-Erstellung (Factory-Pattern oder automatische Registierung bei einer 
	Manager-Klasse im Konstruktor), oder über \lstinline|dynamic_cast<>()|'s und anschließendes Auslesen von spezifischer
	Meta-Information ermitteln, oder aber durch "`property flags"', also Bit-Flags, die Features einer Scene Node andeuten.
	Welche dieser Methoden langfristig die robusteste, flexibelste und eleganteste ist,
	vermag ich noch nicht zu sagen. Da Typ-Informationen über \lstinline|enum|s 
	(als Bitflags oder "`normale"' Aufzählungstypen)
	eine gewisse Redundanz haben ggü. der dynamischen Typ-Information, die C++ bereit stellt, und außerdem eine weitere
	Fehlerquelle für den Programmierer darstellen, sind die Bitflags nicht erste Wahl. Außerdem schränkt die explizite 
	Auflistung von Features womöglich die Erweiterbarkeit des Systems ohne komplette Neu-Kompilierung ein.
	Andererseits machen sie Programme vielleicht lesbarer, indem bestimmte Kategorien/Features explizit aufgelistet 
	(und im Falle von Bitflags beliebig kombinierbar) sind, 
	und nicht implizit in C++-Typinformationen codiert sind.
	Aufzählungstypen werden intensiv in \emph{Flewnit} verwendet. Nicht immer sind diese für die Programmlogik nötig.
	Sie halfen jedoch zur Strukturierung und Ideen-Sammlung. Letztere ist wichtig, da bei einem Softwaresystem,
	welches generische Verwendbarkeit anstrebt, schon weit vor Implementierung konkreter Klassen die Struktur der
	Basisklassen anhand von abstrahierten (erwarteten) gemeinsamen Features der möglichen abgeleiteten Klassen
	möglichst exakt bestimmt werden sollte. Je weiter oben in der Klassenhierarchie Design-Fehler auftreten, desto
	aufwändiger droht das spätere Refactoring zu werden.

%	Die Entscheidung, dass \lstinline|WorldObject| abstrakt sein soll, wurde getroffen, damit keine Funktionalität,
%	die zunächst generisch erscheint, sich aber später als doch nicht allgemein auf alle konkreten 
%	\lstinline|WorldObjects| anwendbar herausstellt, diese Basisklasse verunreinigt. 
%	Es sind so viele verschiedenste Ableitungen denkbar (Rigid Body, Soft Body, rein visuelles Objekt, Kamera,
%	Lichtquelle, Debug-Draw-Objekte, Cloth, Hair, Fluid...)	
  
 
\subsection{Material}  

	Der Begriff "`Material"', der sich in der Computergraphik eingebürgert hat als Beschreibung von visuellen Eigenschaften
	einer Oberfläche, erscheint in diesem Zusammenhang prädestiniert, sich inhaltlich seiner Bedeutung 
	in einem alltäglichen, nicht computergraphischen Kontext wieder anzunähern:
	das \emph{Material} in \emph{Flewnit} steht für "`sämtliche Eigenschaften von Materie 
	außer ihrer geometrischen Form und internen Repräsentation dieser"'.

	\begin{figure}[!h]
		\centering
	   	\includegraphics[width=0.3\textwidth]{velvetBlack1.jpg}
		\caption{ Der Begriff \emph{Material} mit einer physikalisch orientierten Bedeutung:
			sämtliche Eigenschaften von Materie	außer ihrer geometrischen Form.
			(Bild entnommen aus \cite{microfacet})
		}
		\label{fig:material}
	\end{figure}
	
	Würden wir über die entsprechende Rechenleistung verfügen und als Programmierer das physikalische Know-How
	besitzen (z.B. über Maxwell'sche Gleichungen), bräuchte man dieses Konzept gar nicht weiter zu konkretisieren,
	und könnte sämtliches Verhalten von Simulations-Objekten durch subatomare Material-Eigenschaften modellieren.
	Dies wäre eine "`echte"' Vereinheitlichung der bestehenden Engine-Konzepte, die unserer Realität Rechnung trüge.
	Da wir jedoch realistisch (im Sinne der Machbarkeit) bleiben wollen und jetzt und heute Echtzeit-Fähigkeit,
	auch auf Kosten von physikalischer Korrektheit/Genauigkeit anstreben, sind Domänen-spezifische Konkretisierungen des
	Material-Konzeptes notwendig, und wie so viele andere Klassen in diesem System wird die 
	\lstinline|Material|-Klasse zur abstrakten Oberklasse.
	Bei einem \lstinline|SubObject|, welches der visuellen Simulationsdömane angehört, wird implizit erwartet,
	dass das genutzte \lstinline|Material| ein \lstinline|VisualMaterial| ist 
	(mit Texturen, Shader, und verschiedenen Meta-Informationen, um das visuelle Rendering zu delegieren, 
	und in der mechanischen Domäne muss es ein \lstinline|MechanicalMaterial|(mit Eigenschaften wie Masse, Reibung, 	
	Elastizität etc.) sein. Diese domänenspezifischen Material-Typen können oder müssen (je nach Typ des nutzenden
	\lstinline|WorldObject|s) noch weiter abgeleitet sein.
	
	Die Routinen
	\begin{lstlisting}
virtual void activate(
		SimulationPipelineStage* currentStage,
		SubObject* currentUsingSuboject) throw(SimulatorException){}
//undoing stuff, like e.g. re-enable depth test etc.
virtual void deactivate(SimulationPipelineStage* currentStage,
		SubObject* currentUsingSuboject) throw(SimulatorException){}
	\end{lstlisting}
	sind dem Statemachine-basierten visuellen Rendering mit OpenGL zu verdanken und müssen daher von den
	\lstinline|VisualMaterial|-Klassen implementiert werden. Um der Möglichkeit Rechnung zu tragen, dass
	ähnlich State-basierte Mechanismen an anderer Stelle als beim OpenGL-Rendering vorkommen sollten, sind diese
	Routinen in die Oberklasse gelangt.

	

    	
\subsection{Die Buffer-Abstraktion}  
	%Abschnitt ausgelagert weil er zu groß wurde!
	\input{BufferAbstraktion.tex}
		



\subsection{Geometry}
	\label{sec:geometry}
	Die \lstinline|Geometry|-Klasse bildet die abstrakte Basisklasse verschiedenster geometrischer Reräsentationen.\\
	%\footnote{und ergänzt und bildet somit in Kombination  mit dem \lstinline|Material| eine Manifestation eines 
	%materiellen Objektes}.
	Beispiele solcher Repäsentationen sind:
	\begin{itemize}
		\item Vertex-basiert:  Punkte, Linien(-Züge), Dreicke, Quads und beliebige Polygone lassen sich theoretisch
		aus ihnen konstruieren \footnote{theoretisch deshalb, weil z.B. OpenGL maximal Dreiecks-Primitive unterstützt, im 
		Falle von Tessellation noch Quads, aber das ist buchstäblich ein anderes Kapitel}
		\item Voxel-basiert
		\item Freiform-Flächen-basiert: NURBS, Bézier-Patches etc.
		\item Primitiv-Basiert: das Objekt ist aufgebaut aus Primitiven wie Quader, Kugel, Kapseln, Zylindern etc.;
			diese Repräsentation wird gerne für Collision Shapes bei der mechanischen Simulation von Rigid Bodies 
			verwendet.
	\end{itemize}
	Die Repräsentationen überschneiden sich in ihren Kategorisierungen und Eigenschaften, eine sinnvolle Strukturierung ist 
	also weder trivial noch womöglich eindeutig. Die API-Spezifischen Beschränkungen erleichtern diese Aufgabe nicht 
	gerade, wenn man das effiziente Mapping auf eine API im Hinterkopf behalten muss.
	Ich habe mir nicht weiter den Kopf zerbrochen, auch, weil mir spezifisches Wissen z.B. über Primitiv-basierte
	Rigid Body- Simulation fehlt. So wurde sich pragmatisch in der exemplarischen Implementierung auf die
	beiden Basis-Repräsentationen beschränkt, die bei aktuellem visuellen Echtzeitrendering und interaktiver
	Fluidsimulation die wichtigste Rolle spielen: Vertex- und Voxel-basiert. Hierbei sind auch API-spezifische Überlegungen
	mit eingeflossen. Man muss abwägen zwischen der konzeptionell saubersten und umfassendsten Lösung
	und der effizienten Realisierbarkeit mit verfügbaren Hard- und Software-Architekturen.
	im Zweifelsfalle siegt das Konzept, was die effiziente Realisierbarkeit begünstigt.\\
	
	Die Basisklasse hat die Methode
	\begin{lstlisting}	
virtual void draw(
	unsigned int numInstances=1,
	GeometryRepresentation desiredGeomRep = DEFAULT_GEOMETRY_REPRESENTATION ) = 0;
	\end{lstlisting}
	
	\lstinline|numInstances| findet beim Hardware-Instancing Verwendung (s. Abschnitt \ref{sec:instancing}),
	\lstinline|desiredGeomRep| bietet die Möglichkeit -- sofern kompatibel -- für den aktuellen Draw-Call
	eine andere Repräsentation zu wählen. So lassen sich z.B. gezielt bestimmte Dreiecks-Meshes als Linen
	oder Punkte zeichnen, ohne dass andere Objekte beeinflusst würden, wie es bei einer globalen Einstellung 
	der Fall wäre (z.B. über \lstinline|glPolygonMode(GL_FRONT_AND_BACK, GL_LINE)|).
	
	\subsubsection{BufferBasedGeometry}
		Diese Klasse ist ebenfalls noch abstrakt. Sie ist die Basis für alle Klassen, deren geometrische
		Repräsentation ein 1:1-Verhältnis zwischen all ihren Attributen aufweist, also keine komplexen
		Datenstrukturen benötigt. 
		Abgeleitet hiervon sind \lstinline|VertexBasedGeometry| (siehe Abschnitt \ref{sec:VertexBasedGeometry})
		und \lstinline|VoxelGridGeometry| (nicht implementiert).\\
		
		\lstinline|BufferBasedGeometry| hat ein Array von \lstinline|BufferInterface|-Pointern als Member,
		welches über den \lstinline|BufferSemantics|-Aufzählungstyp indiziert werden kann:
		\begin{lstlisting}			
BufferInterface* mAttributeBuffers[__NUM_VALID_GEOMETRY_ATTRIBUTE_SEMANTICS__];
		\end{lstlisting}	
		Diese Buffers können über 
		\begin{lstlisting}			
virtual void setAttributeBuffer(BufferInterface* buffi);
		\end{lstlisting}
		gesetzt werden.  Die Position in \lstinline|mAttributeBuffers| wird von der Semantik von \lstinline|buffi| 
		bestimmt. Die Methode ist virtuell, da sie von \lstinline|VertexBasedGeometry| 
		für das Setzen des entsprechenden OpenGL-States überschrieben werden muss.		
		
		Zur Information, falls man mit dem System eine Voxel-basierte Simulation plant:\\
		\lstinline|VoxelGridGeometry|  könnte als konkrete Attribute-Buffers
		entweder 3D-Texturen oder einen generischen Buffer haben. Hier tut sich ein Problem auf:
		Das Schreiben in 3D-Texturen ist zwar als OpenCL-Extension verfügbar, wird aber zumindest noch nicht
		von Nvidia-Treibern unterstützt, evtl. noch nicht einmal nativ von der Hardware (hierüber habe ich keine
		Informationen gefunden).
		Folglich würde man einen generischen Buffer verwenden wollen.
		Dieser lässt sich jedoch nicht mehr direkt per OpenGL via Ray-Casting visualisieren.
		Abhilfe könnte schaffen, dass man eine Textur allokiert, diese jedoch an OpenCL als klassischen Buffer übergibt.
		Derartige Mechanismen stellt OpenCL jedoch nicht bereit. In CUDA ist es zumindest möglich, einen generischen 
		Buffer als Textur zu binden, darüber, ob es umgekehrt auch geht, habe ich keine offizielle Information, halte
		es jedoch für unwahrscheinlich 
		\footnote{Texturen liegen intern so im Speicher, dass eine gute 2D-räumliche Lokalität gewährleistet ist, z.B.
		über eine Z-Order-Curve (siehe \cite{internet:zOrderCurve}). Auf diese Weise werden Cache Misses und 	
		benötigte Bandbreite reduziert. Dieses Layout is non-disclosed, entsprechend ist es unwahrscheinlich,
		dass man in CUDA Texturen als generische Buffer binden kann, denn für definierten Zugriff über normale
		Adressen und Offsets müsste man das Daten-Layout kennen.}.
		3D-Image Writes sind auch in CUDA noch nicht möglich. Man scheint sich also immer noch
		mit Work-Arounds behelfen zu müssen, wie 3D-Texturen in 2D-Texturen zu encoden oder pro Frame von einem Buffer
		in eine 3D-Textur zu kopieren.\\
		Auch wenn das beschriebene Phänomen die partikelbasierte Fluidsimulation dieser Arbeit nicht betrifft, 
		ist es doch bemerkenswert, dass bei all den
		Fortschritten, die Hardware und APIs gemacht haben, teils immer noch Beschränkungen wie diese
		existieren.


	\subsubsection{VertexBasedGeometry}
	\label{sec:VertexBasedGeometry}
	
	Diese Klasse abstrahiert das OpenGL Vertex Buffer Object(VBO).
	
	Wie in den Textur- und Buffer-Klassen selbst, wird auch hier die \lstinline|BufferInfo|-Klasse genutzt,
	um die relevanten Parameter (Datentyp und dessen Bit-Count, 
	Anzahl Channel-Komponenten, Normalisierungs-Flags, BufferSemantics als Attribute Index, 
	s. Seite \pageref{item:BufferSemantics}) der VBO-bezogenen API-Calls zu bestimmen .
	
	Die Klasse hat zusätzlich zu den Attribute Buffers einen Pointer, der optional als Vertex Index Buffer
	gesetzt werden kann. Dann wird der OpenGL- Draw Call über \lstinline|glDrawElementsInstanced(..)|
	getätigt.
	Zusätzlich kann man optional ein Intervall angeben, welcher Bereich 
	im Index Buffer genutzt werden soll.
	Dies ist z.B. sinnvoll, wenn mehrere logische Objekte mit verschiedenen Materials in einem Buffer
	liegen, wie es z.B. bei einer Fluidsimulation der Fall ist, in welcher mehrere Fluide und Rigid Bodies sich
	ein Attribute Buffer Set teilen. So kann man kontrollieren, was im Buffer gezeichnet werden soll und was nicht.
	In diesem Fall wird \lstinline|glDrawElementsInstancedBaseVertex(..)| für den OpenGL- Draw Call genutzt.
	
	Ist kein Index Buffer gesetzt, werden die Vertices über \lstinline|glDrawArraysInstanced(..)|	
	 "`direkt"' gezeichnet, also wird z.B. angenommen, dass drei hintereinander liegende Vertices ein Dreick bilden. 
	
	Um bei Ping Pong- Buffers vor dem Draw Call sicher zu gehen, dass der aktive Buffer gebunden ist,
	werden in der \lstinline|draw()|-Routine, falls eine Flag anzeigt, dass Ping Pong Buffers unter den 
	Attribute Buffers sind, diese neu ans VBO gebunden, falls der aktive Buffer seit dem letzten Draw call gewechselt hat.
	
	
	\subsubsection{InstancedGeometry}
	Diese Klasse stellt eine reine "`Dummy-Geometrie"' dar. In ihrer \lstinline|draw()|-Routine teilt sie ihrem
	zugehörigen \lstinline|InstanceManager| nur mit, dass diese Instanz beim nächsten Instanced Rendering-Draw Call
	ebenfalls gezeichnet werden will. Für Details sei auf Abschnitt \ref{sec:instancing} verwiesen.
	
	

\subsection{Das MPP-Paket}

Dieses Paket stellt dem \emph{Flewnit}-System alle Funktionaltät zur Verfügung, die mit
GPU-Programmen zu tun hat, außer der OpenGL-Kontext-Erstellung,
welche vom \lstinline|WindowManager| übernommen wird.


	\subsubsection{MPP und ParallelComputeManager}
	Das \lstinline|MPP|, kurz für "`Massively Parallel Program"', ist die Basis-Klasse für
	\lstinline|Shader| und \lstinline|CLProgram|.
	
	\begin{lstlisting}[escapechar=\%]
class MPP
: public SimulationObject %\footnote{SimulationObject ist schlicht eine Klasse, die Namen und Simulations-Domäne speichert, damit diese nicht überall neu definiert und Getter implementiert werden müssen.}%
{
	FLEWNIT_BASIC_OBJECT_DECLARATIONS;
public:
	MPP(String name, SimulationDomain sd);
	virtual ~MPP();
	virtual void build()=0;
protected:
	virtual void setupTemplateContext(TemplateContextMap& contextMap)=0;
	virtual void validate()throw(SimulatorException)=0;
	//for later debugging of the final code of a stage:
	void writeToDisk(String sourceCode, Path where);
};
\end{lstlisting}



	Die \lstinline|ParallelComputeManager|- Singleton-Klasse erstellt einen OpenCL-Kontext, der für CL/GL-Interoperabilität 
	mit dem (zuvor vom \lstinline|WindowManager| erstellten) OpenGL-Kontext assoziiert wird.\\
	Dann werden über OpenCL-Queries die Members einer \lstinline|ParallelComputeDeviceInfo|-Instanz
	gesetzt, so dass System-global alle relevanten/interessanten Hardware Features bequem verfügbar sind.\\
	
	Die Klasse besitzt die OpenCL-C++-Objekte, die mit dem Kontext assoziiert sind:
	Den \lstinline|cl::Context| selbst, das assoziierte \lstinline|cl::Device| (also für gewöhnlich die
	Repräsentation der GPU des Rechners), und die assoziierte \lstinline|cl::CommandQueue|, in die die einzelnen
	Kernel Launches, Buffer/Image Reads/Writes/Copies, Synchronisations-Punkte etc. eingefügt werden,
	und stellt diese über Getter-Funktionen dem System zur Verfügung.\\
	
	Der OpenCL-C++-Wrapper implementiert Error-Handling inklusive dem Werfen von \lstinline|cl::Exceptions|.
	Bei der OpenGL-C-API muss man Errors aber nach wie vor explizit abfragen. Dieses - mit zusätzlich formatiertem
	Konsolen-Output - übernimmt \lstinline|void checkCLGLErrors()| (checkt auch den letzten CL-Error, einfach zur 
	Vollständigkeit, auch wenn es nicht nötig ist).\\
	Um bei der Entwicklung des Systems	sofort auf OpenGL-Errors aufmerksam gemacht zu werden, ist folgendes Makro
	definiert:
\begin{lstlisting}	
#ifdef _DEBUG
	//Macro to permanently check for errors in debug mode
#	define GUARD(expression) \
	expression; \
	ParallelComputeManager::getInstancePtr()->checkCLGLErrors()
#else
#	define GUARD(expression) expression
#endif
\end{lstlisting}
	Sämtliche OpenGL-Calls sind irgendwie durch dieses Makro eingeschlossen. Der etwaige Performance-Overhead spielt
	durch bedingte Kompilierung im Release-Build keine Rolle.\\
	
	Da auf die Klasse sehr häufig zugegriffen wir, ist das Shortcut-Makro \\
	\lstinline|#define PARA_COMP_MANAGER ParallelComputeManager::getInstancePtr()|\\
	für bequemere Referenzierung der Singleton-Instanz im Code definiert.

	\lstinline|ParallelComputeManager| besitzt sämtliche \lstinline|MPP|-Instanzen, die sich bei ihr über ihren 
	Konstruktor automatisch registrieren,
	und ist für deren Löschung beim Engine-Reset zuständig.\\
	
	Alle \lstinline|BufferInterface|-Instanzen, die sowohl eine OpenCL- als auch eine OpenGL- Repräsentation
	haben, registrieren sich automatisch bei dieser Instanz, so dass die Akquisition von Shared Buffers
	für einen bestimmten Kontext ganz einfach geschehen kann:
	\begin{lstlisting}[escapechar=\%]
void ParallelComputeManager::acquireSharedBuffersForCompute()
{
	//skip if not necessary;
	if(computeIsInControl()) return;
	//force to wait for all GL commands to complete
	barrierGraphics();%\footnote{barrierGraphics() ist schlicht ein Wrapper für GUARD(glFinish()), so wie	barrierCompute() als mCommandQueue.enqueueBarrier() implementiert ist.}%
	mLastCLError = mCommandQueue.enqueueAcquireGLObjects(& mRegisteredCLGLSharedBuffers);
	mCLhasAcquiredSharedObjects = true;
}
	\end{lstlisting}
	\lstinline|void acquireSharedBuffersForGraphics()| ist ähnlich implementiert.\\
	
	Ob Buffer-Operationen mit dem Host-Code synchronisiert werden sollen 
	(also ob API-Calls wie \lstinline|cl::CommandQueue::enqueueWriteImage(..)| bis zum Beenden der Buffer-Operation
	nicht zurückkehren sollen) oder nicht, lässt sich global über \lstinline|void setBlockAfterEnqueue(cl_bool val)|
	und \lstinline|cl_bool getBlockAfterEnqueue()const| setzen bzw abfragen 
	(vgl. Listing \ref{listing:bufferOpImpls_Buffer} ff.).
	Letztendlich hat sich jedoch herausgestellt, dass Blocking bei Write-Operationen nicht nötig ist, weil ich
	(zumindest bei Kernel Launches) intensiv von 
	\lstinline|cl::Events| Gebrauch mache, von denen man Listen als Parameter an 
	\lstinline|cl::CommandQueue::enqueueXY()|
	übergeben kann, und dieser Command wird frühestens dann ausgeführt, wenn alle Commands, die mit der Event-Liste
	assoziiert sind, vollständig ausgeführt sind. Blocking von Buffer-Operationen ist also nur dann nötig, wenn man nach
	einem 	Read-Back sofort im Host-Code die ausgelesenen Werte benötigt. Beim Design hätte man sich noch mehr auf den
	Event-Waiting-Mechanismus fokussieren sollen, der zur Zeit vom \lstinline|Bufferinterface| noch nicht unterstützt ist.
	Das \lstinline|BufferInterface| sollte so schlicht wie möglich gehalten sein. 
	Momentan kommt deshalb die Synchronisation von Buffer-Operationen etwas holprig daher. 
	Man kann den Design Flaw umgehen, indem man vor einer Buffer-Operation
	\lstinline|PARA_COMP_MANAGER->getCommandQueue().enqueueWaitForEvents(eventVector)| aufruft, ein Refactoring ist dennoch 
	in Planung.
	
	%-----------------------------------------------------------------------------------------------------------
	
	\subsubsection{Shader und ShaderManager}
	\label{sec:Shader}
		
		Die \lstinline|Shader|-Klasse wrappt erwartungsgemäß die OpenGL-Shader-Funktionalität,
		stellt außerdem Convenience Functions zum Setzen von Uniform Variablen bereit, deren Kontrollfluss
		z.T. von den \lstinline|ShaderFeaturesLocal| und den \lstinline|ShaderFeaturesGlobal| abhängt.
		Das \lstinline|MPP|-Interfaces ist implementiert, jedoch noch ableitbar.
		Nur die neue Routine  \lstinline|virtual void use(ubObject* so)throw(SimulatorException)=0;|
		ist rein abstrakt.\\
		
		Inwiefern das Shader-Interface und seine Implementatioen geschickt und generisch gewählt sind
		oder nicht, konnte leider empirisch noch nicht umfassend ermittelt werden, da bisher der
		Shader-Template-Code aller abgeleiteten
		Shader-Klassen auf eine einzige Sammlung von Dateien zurück gehen, nämlich der mit dem suggestiven Namen
		"`GenericLightingUberShader"'. diese realisiert sowohl das klassische visuelle Rendering mit den in Abschnitt
		\ref{sec:usedOpenGLfeatures} vorgestellten Features, als auch die Shadow Map Generation und die
		Debug-Draw-Funktionalität.\\
		Die wahre Probe für die \lstinline|Shader|-Klasse erfolgt jedoch, wenn eine Datei-Sammlung und mit ihr
		eine (Multi-Pass)-Shaderstruktur, die nicht viel mit dem "`GenericLightingUbershader"' gemeinsam hat,
		zur Code-Basis wird. Inwiefern die Convenience Functions dann noch sinnvoll sind,
		(nicht-virtuell) in der Shader-Oberklasse definiert zu sein, ist zur Zeit noch schwer abschätzbar.
		Ob trotz der signifikanten Unterschiede diese Klasse gut abstrahiert ist und so allgemein nutzbar bleibt,
		wird sich erst dann herausstellen, wenn die  \lstinline|ParticleLiquidDrawStage| 
		(s. Abb. \ref{fig:detailSimulator}) implementiert ist. 
		Aus Zeitmangel konnte das Fluid noch nicht angemessen visualisiert werden, das 
		\lstinline|LiquidVisualMat| ist momentan noch 
		-- entgegen dem Klassendiagramm in Abb. \ref{fig:ClassDiagOverview2} --
		"`hacky"' von \lstinline|DegugDrawVisualMat| abgeleitet.\\
		In Anbetracht eines solchen nicht unerheblichen Vollständigkeits-Mangels bei der Implementierung 
		sei hier explizit auf Abschnitt \ref{sec:statusImplementation} verwiesen, der den Status der Implementierung
		zur Zeit der Abgabe der Ausarbeitung skizziert.\\
	
	
	Die \lstinline|ShaderManager|-Singleton-Klasse hat zum Ziel, möglichst viele visuelle Rendering-Techniken und -Effekte 
	in beliebigen (sinnvollen) Permutationen zu ermöglichen. Um nicht hunderte Shader
	von Hand anlegen zu müssen, die vor Boilerplate-Code überlaufen, wird wie gesagt die
	\emph{Grantlee}-Template-Engine verwendet, um aus relativ wenigen Dateien angepasste Shader zu generieren.
	
	Sie ist dafür zuständig, immer wenn sich das "`Rendering Szenario"' ändert, also eine neue 
	\lstinline|LightinSimStageBase| im \lstinline|LightingSimulator| aktiv wird,  anhand von diversen Parametern
	allen \lstinline|VisualMaterial|s einen zum Material, dem Szenario und den globalen Shader-Features
	kompatiblen \lstinline|Shader| zuzuweisen. Dieser wird entweder zur Laufzeit
	per \emph{Grantlee} generiert, oder wenn schon ein Shader mit benötigten Features existiert, aus einer
	Hash-Map beschafft, wo der Hash-Wert der Shader-Features als Schlüssel dient.
	Das Sequenz-Diagramm in Abb. \ref{fig:shaderGen} skizziert den Ablauf.
	
	Außerdem lassen sich einige Features abfragen, die ansonsten nur indirekt in den Feature-Structures
	encoded sind, wie z.B. ob die aktuelle Stage einen Framebuffer braucht oder nicht.
	
	\begin{figure}[!h]
	\includegraphics[width=1.09\textwidth]{ShaderGeneration.pdf}
	\caption{Sequenz-Diagramm der Shader-Generierung}
	\label{fig:shaderGen}
	\end{figure}
	
	Die Parameter sind:	
	\begin{description}
	
	
		\item[ShaderFeaturesGlobal] Parameter, die global per Config gesetzt wurden und ohne Reset der Engine nicht
			mehr zu ändern sind, und aufgrund von Buffergrößen, Kompatibilitäten und/oder der schlichten Konsitenz
			des visuellen Renderings sich zwischen den einzelnen Shadern nicht unterscheiden dürfen. dazu zählen:
		 	\begin{itemize}
		 	\item die maximale Anzahl an Lichtquellen
		 	\item die maximale Anzahl an Lichtquellen, die Schatten werfen (Shadow Caster),
		 	\item die maximale Anzahl an Instanzen, die pro Draw Call per Hardware Instancing gezeichnet werden kann
		 	\item falls man Deferred Rendering betreibt:
		 		 Der Textur-Typ des G-Buffers (\lstinline|Texture2D, Texture2DMultisample| etc.),
		 	\item falls man Deferred Rendering betreibt: Der MultiSample-Count des G-Buffers, falls er aus 
		 		MultiSample-Texturen besteht
		 	\item das
		 	\begin{lstlisting}
enum LightSourcesLightingFeature
{
	LIGHT_SOURCES_LIGHTING_FEATURE_NONE						=0,
	LIGHT_SOURCES_LIGHTING_FEATURE_ONE_SPOT_LIGHT			=1,
	LIGHT_SOURCES_LIGHTING_FEATURE_ONE_POINT_LIGHT			=2,
	LIGHT_SOURCES_LIGHTING_FEATURE_ALL_POINT_LIGHTS			=3,
	LIGHT_SOURCES_LIGHTING_FEATURE_ALL_SPOT_LIGHTS			=4,
	LIGHT_SOURCES_LIGHTING_FEATURE_ALL_POINT_OR_SPOT_LIGHTS	=5,
	__NUM_LIGHT_SOURCES_LIGHTING_FEATURES__					=6
}; 
		 	\end{lstlisting}
		 	Dieser Aufzählungstyp delegiert bei der Shader-Generierung per Template-Engine, welche Typen 
		 	und welche Anzahl an Lichtquellen vom Shader unterstützt werden sollen.
			\item das
		 	\begin{lstlisting}		 	
enum LightSourcesShadowFeature
{
	LIGHT_SOURCES_SHADOW_FEATURE_NONE			=0,
	LIGHT_SOURCES_SHADOW_FEATURE_ONE_SPOT_LIGHT	=1,
	LIGHT_SOURCES_SHADOW_FEATURE_ONE_POINT_LIGHT	=2,
	LIGHT_SOURCES_SHADOW_FEATURE_ALL_SPOT_LIGHTS	=3,
	__NUM_LIGHT_SOURCES_SHADOW_FEATURES__		=4
};	
		 	\end{lstlisting}
		 	Es gibt an, ob und wenn ja, welche Art Shadow Mapping vonstatten gehen soll.
		 	
		 	\item das
		 	\begin{lstlisting}
enum ShadowTechnique
{
	SHADOW_TECHNIQUE_NONE		=0,
	SHADOW_TECHNIQUE_DEFAULT	=1,
	SHADOW_TECHNIQUE_PCFSS		=2,
	__NUM_SHADOW_TECHNIQUES__	=3
};		 	
		 	\end{lstlisting}
		 	, welches bestimmt, nach welchem Algorithmus Shadowmapping vonstatten gehen soll
		\end{itemize}
		
		
		
		\item[diverse ShadingFeatures] 
		Diese Flags geben an, welche Shading-Features "`aktiv"' sind: Die \lstinline|ShadingFeatures| des letztendlich
		generierten Shaders hängen von den Shading Features des Materials selbst ab, aber auch von denen der 
		aktuell aktiven \lstinline|LightinSimStageBase| (eine \lstinline|ShadowMapGenerationStage| hat z.B. gar keine
		"`Shading"'-Features) und von den aktuell global aktivierten Features. Welche Features global aktiv sind, kann
		vom Benutzer bestimmt werden, hängt aber z.T. auch von der verwendeten OpenGL-Version ab. Tessellation kann z.B. 
		erst ab OpenGL 4.0 verwendet werden.
		
		\begin{lstlisting}
enum ShadingFeatures
	{
	SHADING_FEATURE_NONE				=1<<0,
	SHADING_FEATURE_DIRECT_LIGHTING		=1<<1,
	//global lighting via layered depth images or stuff... just a brainstroming, wont be implemented
	SHADING_FEATURE_GLOBAL_LIGHTING		=1<<2,
	SHADING_FEATURE_DIFFUSE_TEXTURING		=1<<3,
	SHADING_FEATURE_DETAIL_TEXTURING	=1<<4,
	SHADING_FEATURE_NORMAL_MAPPING		=1<<5,
	SHADING_FEATURE_CUBE_MAPPING		=1<<6,
	SHADING_FEATURE_AMBIENT_OCCLUSION	=1<<7,
	SHADING_FEATURE_TESSELATION			=1<<8,
	__NUM_SHADING_FEATURES__			=9
};
	\end{lstlisting}
		
		
	\item[VisualMaterialType]
	Der Typ bestimmt für gewöhnlich die Klasse des konkreten Shaders (erinnere: \lstinline|Shader| ist eine abstrakte 
	Basisklasse):	
	\begin{lstlisting}
enum VisualMaterialType
{
	VISUAL_MATERIAL_TYPE_NONE					=0,
	VISUAL_MATERIAL_TYPE_DEFAULT_LIGHTING  		=1,
	VISUAL_MATERIAL_TYPE_SKYDOME_RENDERING		=2,
	VISUAL_MATERIAL_TYPE_DEBUG_DRAW_ONLY		=3,	//just set a color value or something
	VISUAL_MATERIAL_TYPE_GAS_RENDERING			=4,
	VISUAL_MATERIAL_TYPE_LIQUID_RENDERING		=5,
	__NUM_VISUAL_MATERIAL_TYPES__				=6
};
	\end{lstlisting}
	
	
	\item[VisualMaterialFlags]
	Diese Klasse trägt nicht nur zur Delegation der Shader-Generierung bei, sie
	gibt auch bei einem \lstinline|VisualMaterial| bestimmte Eigenschaften an,
	welche auf Kompatibilität mit den Flags der aktuellen \lstinline|LightingSimStageBase| getestet werden können.
	Auf diese Weise können inkompatible Objekte maskiert werden.
	Der Konstruktor reicht aus für eine Idee:
	\begin{lstlisting}
VisualMaterialFlags(
	bool castsShadows = true,
	bool isTransparent = false,
	bool isShadable = true,
	bool isDynamicCubeMapRenderable = true,
	bool isInstanced=false,
	bool isCustomMaterial=false);
	\end{lstlisting}
		
	\end{description}
	
	%\sectionlevelfour{Probleme}
	\paragraph{Probleme}
	Es sei noch ein nicht so unwichtiges Wort verloren über den Versuch, viele Effekte und Techniken in beliebiger
	Permutation zu kombinieren: Da dank der Template-Engine nun die Möglichkeit besteht, in Vererbungs-Hierachien zu denken
	und somit objektorientierte Ansätze ins Shader-Design einfließen zu lassen, zeigt sich umso krasser,
	wie schwer es ist, Effekte und Techniken sauber und modular zu kombinieren, wenn man obendrein noch maximale
	Performance haben will.\\
	Viele Features in einem Shader bringen bei Integration neue Einschränkungen mit sich, 
	die besonderer Behandlung bedürfen.
	Ein Beispiel ist die Kombination von Tessellation mit Shadow Mapping und/oder Layered Rendering: 
	Hier tut sich das Problem auf, dass wir zur Shadowmap-Generierung aus Sicht der Lichtquelle rendern 
	(die View-Matrix ist aus Position und Richtung der \emph{Lichtquelle} konstruiert), wir aber für Level-Of-Detail-	
	Berechnungen zur Bestimmung des Tessellation-Levels	Vertex-Positionen im \emph{Betrachter}-Viewspace benötigen!
	Dies hat den Grund, dass das LOD eines jeden Patches sowohl in der Shadow Map als auch im finalen Rendering
	gleich sein müssen! Wenn dies nämlich nicht der Fall ist, ist die Geometrie, die dem Shadow-Map-Lookup
	zugrunde liegt, eine andere als die des finalen Renderings. somit werden sprichwörtlich Äpfel mit Birnen verglichen,
	und es kann zu Artefakten kommen, z.B. Selbstverschattung, wo keine sein sollte (wenn durch Tessellation z.B.
	eine Furche generiert wird und die Lichtquelle weiter weg von der Geometrie ist als die Betrachter-Kamera, 
	s. Abb. \ref{fig:tessellationSelbstverschattung}).
	
	\begin{figure}[!h]
	\includegraphics[width=\textwidth]{tessellationSelbstverschattung.pdf}
	\caption{Artefakte bei naiver Tessellation-Level-Berechnung mit Camera-Viewspace bei der Shadow Map Generation}
	\label{fig:tessellationSelbstverschattung}
	\end{figure}
	
	Um diese Artefakte zu vermeiden, muss für die LOD-Berechnung im Tesselation Control Shader
	\emph{immer} die Viewspace-Position der Vertices aus Sicht der Betrachter-Kamera zur Verfügung stehen.
	Bei der Shadow-Map-Generierung und/oder bei Layered Rendering (in Cube Maps und/oder Texture Arrays)
	werden aber für alles weitere, wie Displacement Mapping im Tessellation Evaluation Shader oder Beleuchtung
	im Fragment Shader, Viewspace-Positionen aus \emph{Lichtquellen}-Sicht bzw \emph{Worldspace}-Positionen durch die
	einzelnen Shader Stages geschleift.\footnote{bei Layered Rendering muss man bis zur Geometry Shader Stage im 
	World Space (nur mit der Model Matrix) rechnen, da im Geometry Shader jedes Layer eine andere Kamera, also eine andere 
	View Matrix hat. Entsprechend kann  man keine ModelView Matrix für frühzeitige View Space-Berechnungen akkumulieren!}
	Somit sind die klassischen Interface-Varying-Variablen schon belegt.
	Man muss also eine neue Variable benutzen, um die Betrachter-Kamera-View Space-transformierte Vertex-Position
	vom Vertex Shader an den Tessellation Control Shader zu übergeben. Da die built-in-Variable
	\lstinline[language=GLSL]|gl_Position| für OpenGL erst direkt vor der Fragment Shader-Stage für die Rasterisierung
	benötigt wird, kann man sie zuvor einfach zum Durchschleifen beliebiger Werte zweckentfremden. Somit ergibt sich
	folgender Vertex Shader Template-Code:
	\begin{lstlisting}[language=GLSL]
// step 2: calculate the gl_Position, if necessary 
{%if not layeredRendering and not SHADING_FEATURE_TESSELATION %} 
  //default case:
  //we need projected transform for rasterization because no tessCtrl/TessEval/geom shader follows the vertex shader;
  gl_Position =  modelViewProjectionMatrix  * inVPosition; /*default MVP transform*/   
{% endif %} 
{%if SHADING_FEATURE_TESSELATION %} 
  {%if RENDERING_TECHNIQUE_SHADOWMAP_GENERATION %}
    //write the "spectator view space position" to gl_Position for tessellation LOD calculations 
    gl_Position =  spectatorCamViewMatrix * (modelMatrix * inVPosition);
  {% else %}
    {% if worldSpaceTransform  %}
      //write the "own view space position" to gl_Position for tessellation LOD calculations; 
      //Hence, even for dynamic cubemap generation, a modelViewMatrix must be passed 
      //to the vertex shader for this scenario;
      //The tessellation LOD calculation is invariant to cam rotation, 
      //hence only the translational part of the view matrix
      //is relevant, and this part is equal for every six cube map faces;
      gl_Position =  modelViewMatrix * inVPosition;
    {% endif %}
  {% endif %}
{% endif %}
	\end{lstlisting}
	
	und für den Tesselation Control Shader:
	
	\begin{lstlisting}[language=GLSL]
//In order to determine the tessellation levels,
//we need all three vertex positions in spectator view space 
//of the triangle patch to which the current vertex belongs:
{%if RENDERING_TECHNIQUE_SHADOWMAP_GENERATION or worldSpaceTransform %}
  //every user varyings are either in spectator world space
  //or in the light source- view- or world space;
  //but we need the VIEW space vertex positions seen from the SPECTATOR camera for the tessellation level calculations!
  //The vertex shader has written this value to gl_Position:
  vec3 edgeStart = gl_in[ (gl_InvocationID + 1) % 3 ].gl_Position.xyz;
  vec3 edgeEnd   = gl_in[ (gl_InvocationID + 2) % 3 ].gl_Position.xyz;
  vec3 ownVert   = gl_in[  gl_InvocationID          ].gl_Position.xyz;
{% else %}
  //no special case, we do just default rendering in spectator- view space; So grab the default position value:
  vec3 edgeStart = input[ (gl_InvocationID + 1) % 3 ].position.xyz;
  vec3 edgeEnd   = input[ (gl_InvocationID + 2) % 3 ].position.xyz;
  vec3 ownVert   = input[  gl_InvocationID          ].position.xyz;  
{% endif %}  
	\end{lstlisting}
	
	
	Das Fazit ist: Modulares Shader-Design, welches effizienten Code produziert, scheint je nach Feature-Set
	schwer bis unmöglich. Das Nutzen von Vererbungsmechanismen wird durch die notwendigen Spezial-Behandlungen 
	ebenfalls erschwert.
	Vor der Integration weiterer Features in diesen Uber Shader muss die Struktur überarbeitet werden.
	Ich war zur Zeit des Schreibens des Shader-Codes weder mit dem Templating vertraut, noch habe ich alle Spezialfälle
	antizipieren können. Mit neuen Einsichten und Erfahrungen werden Les- und Erweiterbarkeit
	vom Shader-Code durch ein Refactoring hoffentlich verbessert werden können.
	Ferner sollen dann geeignete Wege gefunden werden, Komplexität mithilfe von Vererbungsmechanismen
	besser zu handhaben, trotz Problemen wie dem vorgestellten.\\
	All diese Probleme betreffen nur den Shader-Code. Insbesondere die Vererbungsmechanismen
	lassen sich in OpenCL-Code-Templates reibungslos nutzen.


	%----------------------------------------------------------------------------------------------------------
		
	\subsubsection{CLProgram und CLProgramManager}
	\label{sec:CLProgram}
	
	\lstinline|CLProgram| und \lstinline|CLKernel| wrappen die entsprechende OpenCL-Funktionalität:
	Das Programm repräsentiert den kompletten ausführbaren Code, welcher aus einem in OpenCL C geschriebenen
	Source Code kompiliert wurde. Ein Kernel ist dagegen eine von womöglich mehreren Funktionen innerhalb
	des Programmmes (durch das \lstinline[language=OpenCL]|__kernel|-Tag gekennzeichnet),
	welche vom Hostcode per \lstinline|cl::CommandQueue::enqueueNDRangeKernel()| aufgerufen werden kann.
	Es besteht also eine $1:n$-Relation zwischen Programm und Kernel.
	
	Die \lstinline|CLProgramManager|-Singleton-Klasse gewährleistet einen Zugriff auf sämtliche OpenCL-Programme
	im System über ihren Namen. Dies kann nützlich sein, wenn ein Kernel auf die Beendigung eines anderen Kernels
	warten muss, dafür das Event, was mit der letzten Ausführung assoziiert ist, benötigt, aber kein Handle auf die 
	entsprechenen \lstinline|CLProgram|s vorhanden ist.
	
	\lstinline|CLProgramManager| besitzt einen \lstinline|IntermediateResultBuffersManager|, der Buffers bereit stellt,
	die sich verschiedene Kernels für ihre Zwischen-Ergebnisse teilen können. Somit wird GPU-Speicher gespart.
	Jedes \lstinline|CLProgram|, welches Kernels hat, die Zwischenergebnisse benötigen, kann eine bestimmte Menge
	und Größe an Buffers requesten. Es ist dann sichergestellt, dass der Buffer mit entsprechendem Index nach 
	Allokation (geschieht nach Erschaffung sämtlicher \lstinline|CLProgram|-Instanzen) mindestens die
	gewünschte Größe hat.
	 
	
		
		%\sectionlevelfour{CLKernelArguments}
		\paragraph{CLKernelArguments}
		\label{sec:CLKernelArguments}
		Der Umgang mit Kernel-Argumenten, also Parametern, die an die Kernel-Funktionen übergeben werden, 
		wird durch die Klasse \lstinline|CLKernelArguments| und seine Members deutlich erleichtert:
		In OpenCL kann man Werte an Kernels nur über ihren Index in der formalen Parameter-Liste übergeben.
		Diese holprige Methode ist nicht nur im Code wenig aussagekräftig, sie birgt auch die Gefahr,
		dass wenn Kernel-Signaturen sich ändern, im Host-Code genutzte Indices invalid werden.
		Wenn diese auch noch verteilt im System auftauchen, werden der Aufwand und die 
		Fehlerwahrscheinlichkeit noch größer, seinen Host-Code anzupassen. 
		Aus diesem Grund erstellt jedes konkrete \lstinline|CLProgram| seine eigenen Kernels,
		und erstellt auch eine Liste an Default-Parametern für jeden Kernel. Auf diese Parameter kann nun bequem
		sowohl per Index als auch über den Namen des Arguments zugegriffen werden. Typsicherheit ist ebenfalls
		durch die Template-Klasse \lstinline|CLValueKernelArgument| gewährleistet, wo bei einem falschen
		Cast eine Exception geworfen wird.
		Ferner behebt das \lstinline|CLBufferKernelArgument| das bereits erwähnte Binding-Problem 
		beim Toggle von PingPong-Buffers.\\
		Ein detaillierteres Klassendiagramm zu den OpenCL-relevanten Klassen,
		welches zusätzlich die Call-Hierarchie des Build-Prozesses sowie einer Kernel-Invocation skizziert,
		zeigt Abb. \ref{fig:OCLRelatedClassDiag}.
		
		\begin{figure}[t]
		\includegraphics[width=\textwidth]{CLProgramAndCo.pdf}
		\caption{Klassendiagramm der OpenCL-relevanten Klassen inkl. Skizze der Call-Hierarchie des Build-Prozesses
		sowie dem Kernel-Launch}
		\label{fig:OCLRelatedClassDiag}
		\end{figure}



\subsection{Status der Implementierung am Ende der BA}
\label{sec:statusImplementation}

	Es sollten von Anfang an bei der Planung der \emph{Unified Engine} viele Aspekte berücksichtigt werden,
	damit von vornherein ein flexibles und mächtiges System konzipiert werden konnte.
	Das Potential zur Weiterentwicklung war wichtiger als eine "`schnell gehackte Demo"'.
	Es wurden einige Features realisiert, andere sind nahezu vollständig programmiert, aber noch nie ausgeführt worden.
	%\footnote{Mein Programmierstil ist sehr eigenwillig: ich kann wochenlang programmieren, 
	%ohne einmal compilen, geschweige denn ausführen zu können. Dieser Stil scheint mir bei einem solchen Projekt nicht 
	%völlig verkehrt, da bei der sukkessiven Entwicklung der Fokus auf den Feature-Reichtum dem eines konsitenten 
	%Gesamtsystems vorgezogen werden könnte.}
	Wiederum andere Features liegen als Algorithmen in Textdateien, und 
	es ergab sich noch keine Gelegenheit, diese Algorithmen in Programm-Code zu transformieren.
	Wieder andere Features wurden nur ganz grob im Hinterkopf behalten, um die Wahrscheinlichkeit zu erhöhen, 
	dass sie in ferner Zukunft nahtlos mit den anderen Features integrierbar sind.\\
	Eine Liste dieser Features, mit ihrem entsprechenden Implementations-Status ist in 
	Tabelle \ref{tab:statusImpl1} und \ref{tab:statusImpl2} zu finden.\\
										  

 	\begin{table}[!h]
	 	\begin{minipage}{\textwidth}
  		\begin{tabular}
  		{
  		 l  l | c |
  		}
																	\cline{3-3}
  									&								&	Status \\ 
    	\noalign{\hrule}
    	%-------------------------------------------------------------------------------------------------
    	\multicolumn{1}{|c|}{
    		\multirow{3}{*}{used OpenGL Features}
    	}							& 	Uniform Buffers				&  {\color{green}\checkmark}		\\	
		\multicolumn{1}{|c|}{} 		& 	Instancing					&  {\color{green}\checkmark}
												\footnote{Transformation Matrix set provided per Uniform Buffers} \\	
		\multicolumn{1}{|c|}{} 		& 	Tessellation 
										\footnote{providing dynamic LOD, detail added via Displacement Mapping}
    																&  {\color{green}\checkmark}		\\	
		\noalign{\hrule}
		
    	%-------------------------------------------------------------------------------------------------
 		\multicolumn{1}{|c|}{
    		\multirow{3}{*}{Lighting}
    	}							& 	arbitrary light source amount in Shader	&  {\color{green}\checkmark} 
													    	\footnote{As long as they fit into an Uniform Buffer}	\\    	
    	\multicolumn{1}{|c|}{} 		& 	point light lighting		&  {\color{green}\checkmark}		\\	
    	\multicolumn{1}{|c|}{} 		& 	spot light lighting			&  {\color{green}\checkmark}		\\
    	\multicolumn{1}{|c|}{} 		& 	both point and spot light lighting	&  {\color{green}\checkmark}		\\   	
    	
    	\noalign{\hrule}
    	
    	%-------------------------------------------------------------------------------------------------					
    	\multicolumn{1}{|c|}{
    		\multirow{8}{*}{Deferred Rendering}
    	}							& 	Render to 2D Depth Texture		&  {\color{green}\checkmark}		\\				
		\multicolumn{1}{|c|}{} 		& 	Render to 2D Color Texture		&  {\color{orange}o}		\\		
		\multicolumn{1}{|c|}{} 		& 	Render to MultiSample  Color Texture		&  {\color{orange}o}		\\		
		\multicolumn{1}{|c|}{} 		& 	G-Buffer Fill				&  {\color{orange}o}		\\		
		\multicolumn{1}{|c|}{} 		& 	G-Buffer Shade				&  {\color{orange}o}		\\		
		\multicolumn{1}{|c|}{} 		& 	G-Buffer MultiSample Shade	&  {\color{orange}o}		\\		
		\multicolumn{1}{|c|}{} 		& 	Ambient Occlusion			&  {\color{red}x}		\\			
		\multicolumn{1}{|c|}{} 		& 	Post Processing \footnote{Participating Media, Depth Of Field etc.}	
																	&  {\color{red}x}		\\							
		\noalign{\hrule}
		
		%-------------------------------------------------------------------------------------------------					
		\multicolumn{1}{|c|}{
    		\multirow{4}{*}{Layered Rendering}
    	}							& 	Render to  Cube Depth Texture		&  {\color{orange}o}		\\		
    	\multicolumn{1}{|c|}{} 		& 	Render to  Cube Color Texture		&  {\color{darkred}o}		\\		
		\multicolumn{1}{|c|}{} 		& 	Render to  Depth Texture Array		&  {\color{orange}o}		\\
		\multicolumn{1}{|c|}{} 		& 	Render to  Cube Depth Texture Array		&  -
																	\footnote{only supported in OpenGL 4}\\
																	
		\noalign{\hrule}    	
    	
    	%-------------------------------------------------------------------------------------------------					
		\multicolumn{1}{|c|}{
    		\multirow{4}{*}{Shadow Mapping Support}
    	}							& 	single spot light					&  {\color{green}\checkmark}	\\		
		\multicolumn{1}{|c|}{} 		& 	single point light \footnote{requires render to  Cube Depth Texture}				
																			&  {\color{orange}o}		\\
		\multicolumn{1}{|c|}{} 		& 	multiple spot light \footnote{requires render to Depth Texture Array}				
																			&  {\color{orange}o}		\\
    	\multicolumn{1}{|c|}{} 		& 	multiple point light \footnote{requires render to Cube Depth Texture Array}																							&  -		\\
    				
		\noalign{\hrule}    	
    	
    	%-------------------------------------------------------------------------------------------------					
		\multicolumn{1}{|c|}{
    		\multirow{2}{*}{Shadow Map Sampling}
    	}							& 	default				&  {\color{green}\checkmark}	\\		
		\multicolumn{1}{|c|}{} 		& 	PCFSS				&  {\color{red}x}		\\
    															
																							
		\noalign{\hrule}
		
		%-------------------------------------------------------------------------------------------------					
		\multicolumn{1}{|c|}{
    		\multirow{6}{*}{misc. Shading Features}
    	}							& 	arbitrary (useful) effect combination	
    														&  {\color{green}\checkmark}	\\		
		\multicolumn{1}{|c|}{} 		& 	diffuse texturing	&  {\color{green}\checkmark}	\\	
		\multicolumn{1}{|c|}{} 		& 	detail texturing 
									\footnote{high frequency noise pattern to omit blurry appearance on close-up}
															&  {\color{red}x}	\\	
		\multicolumn{1}{|c|}{} 		& 	Normal Mapping		&  {\color{green}\checkmark}	\\	
		\multicolumn{1}{|c|}{} 		& 	Environment Mapping	&  {\color{green}\checkmark}	\\	
		\multicolumn{1}{|c|}{} 		& 	Sky Dome			&  {\color{green}\checkmark}	\\	
		\multicolumn{1}{|c|}{} 		& 	transparency		&  {\color{red}x}		\\
    																				
		\noalign{\hrule}

  		\end{tabular}	
  	
  		\caption{		
  			Status der Implementation zum Zeitpunkt der Abgabe der Ausarbeitung (englisch wegen vieler Fachbegriffe)
  			Legende: \\
			{\color{green}\checkmark}	$\rightarrow$ implementiert;
			{\color{orange}o}	$\rightarrow$ zu weiten Teilen programmiert, jedoch noch nicht 		
				integriert/ausgeführt/getestet;
			{\color{darkred}o} $\rightarrow$ detailliert konzipiert, jedoch nicht programmiert;
			{\color{red}x}	$\rightarrow$ im System langfristig konzipiert, jedoch nicht programmiert;
			- $\rightarrow$ Unterstützung nicht geplant
			\\
		}
		\label{tab:statusImpl1}
		\end{minipage}
  	\end{table}

 	\begin{table}[!h]
	 	\begin{minipage}{\textwidth}
  		\begin{tabular}
  		{
  		 l  l | c |
  		}
																	\cline{3-3}
  									&								&	Status \\ 
    	\noalign{\hrule}
		
		%-------------------------------------------------------------------------------------------------			
		\multicolumn{1}{|c|}{
    		\multirow{6}{*}{mech. fluid simulation}
    	}							& 	basic efficient SPH mechanics
    									\footnote{see section \ref{sec:fluidSim:ablauf}}
    														&  {\color{green}\checkmark}	\\		
		\multicolumn{1}{|c|}{} 		& 	hardware dependent optimizations
										\footnote{see section \ref{sec:hardwareOptimizations} }
															&  {\color{green}\checkmark}	\\
		\multicolumn{1}{|c|}{} 		& 	algorithmic tricks \& optimizations 
										\footnote{integrate density computation into force kernel,
											less bandwidth consuming integration scheme, 
											see section \ref{sec:ausblick} }
															&  {\color{orange}o}	\\								
		\multicolumn{1}{|c|}{} 		& 	multiple fluids		&  {\color{orange}o}	\\	
		\multicolumn{1}{|c|}{} 		& 	particle Rigid Bodies
															&  {\color{orange}o}	\\	
		\multicolumn{1}{|c|}{} 		& 	static triangle collision mesh
															&  {\color{darkred}o}	\\															
		\noalign{\hrule}
		
		%-------------------------------------------------------------------------------------------------					
		\multicolumn{1}{|c|}{
    		\multirow{5}{*}{vis. fluid simulation 
    			\footnote{implementation of \cite{Green2009FluidRenderingCurvatureFlow} is planned}
    		} 
    	}							& 	debug draw			&  {\color{green}\checkmark}	\\		
		\multicolumn{1}{|c|}{} 		& 	curvature flow		&  {\color{red}x}	\\
		\multicolumn{1}{|c|}{} 		& 	perlin noise		&  {\color{red}x}	\\
		\multicolumn{1}{|c|}{} 		& 	foam rendering		&  {\color{red}x}	\\		
		\multicolumn{1}{|c|}{} 		& 	fresnel effect		&  {\color{red}x}	\\		    																																					
		\noalign{\hrule}
		
  		\end{tabular}	
  	
  		\caption{		
  			Status der Implementation zum Zeitpunkt der Abgabe der Ausarbeitung (Fortsetzung)
		}
		\label{tab:statusImpl2}
		\end{minipage}		
  	\end{table}
  	
  	
  	\begin{figure}[!h]
		\includegraphics[width=1.2\textwidth]{Screenshot_prototypeSceneOverview.png}
		\caption{Überblick über die prototypische Szene}
		\label{fig:Screenshot_prototypeSceneOverview}
	\end{figure}
	
	Abb \ref{fig:Screenshot_prototypeSceneOverview} zeigt einen Screenshot aus \emph{Flewnit} 
	mit der prototypischen Scene. Sie zeigt die interaktive partikelbasierte
	Fluid-Simulation inklusive der Visualisierung des Uniform Grid, eine weitere Box mit 
	\linebreak \lstinline|DebugDrawMaterial|,
	einen Würfel aus Objekten, die per Instancing gezeichnet werden, tesseliert und normal mapped sind,
	einen Sky Dome, und schließlich ein tesselliertes, normal und environment mapped Raptor-Modell.
	Alle Objekte sind mit mehreren Lichtquellen, sowohl Spot als auch Point Lights, in einem Render-Pass beleuchtet.
	Ein Spot Light wirft per Shadow Mapping Schatten.  
	Details werden im Verlauf des Abschnitts \ref{sec:simulation} erläutert.\\
  	
  	Der größte Wermutstropfen bei der Implementierung ist sicherlich die Visualisierung des Fluids, die minimalistischer
  	technisch nicht sein könnte. Die Mechanik der Fluidsimulation stand erst wenige Wochen vor der 
  	Abgabe (die ersten Monate waren rein der Framework-Programmierung und dem nicht-Fluid-bezogenen
  	visuellen Rendering gewidmet), 
  	so dass für eine angemessene Visualisierung des Fluids im Rahmen dieser Arbeit leider keine Zeit mehr blieb.
  	Es soll außerhalb des Rahmens dieser vorgelegten Arbeit "`Screen Space Fluid Rendering with Curvature Flow"' 
  	(siehe \cite{Green2009FluidRenderingCurvatureFlow}) vorgestellte Lösung nach-implementiert werden.
  	
  	Weiterhin fehlen noch sämtliche erweiterten Features und "`a posteriori"'-Optimierungen (also Optimierungen, die 
  	nach der erfolgreichen ersten Implementierung programmiert sind) bei der mechanischen Fluid-Simulation.
  	Der Kernel- und Host-Code für die partikelbasierten Rigid Bodies ist fast komplett programmiert.
  	da der Beginn der Ausarbeitung aber sehr dringend wurde, wurde der Versuchung widerstanden,
  	diesen Code noch zu testen.\\
  	Weiterhin ist geplant, "`static triangle collision meshes"' in die ansonsten partikelbasierte
  	mechanische Simulation integrieren, es liegt allerdings zur Zeit nur der Entwurf 
  	eines Algorithmus zur Voxelisierung von Dreiecken ins Uniform Grid vor
  	(mehr dazu im Ausblick, Kapitel \ref{sec:ausblick}).
  

  	Ferner wurde zwar ein Scene-Loader mithilfe von \emph{Assimp} implementiert, es ist aber noch vieles
  	hart-codiert, so dass das Laden von beliebigen Assets noch nicht möglich ist. Der Fokus lag
  	auf der Realisierung von kombinierbaren Effekten, vorerst nicht auf künstlerischem Anspruch. 
  	Dennoch ist die Fertigstellung des Scene Loaders geplant.
	
	Die fehlende GUI erschwert das Parameter-Tweaken, was zur Zeit noch per XML-Datei geschehen muss.
	
	Für weitere Details im Umgang mit fehlenden Features und unvöllständiger Implementation sei auf
	den Ausblick in Abschnitt \ref{sec:ausblick} verwiesen.

\clearpage
